# Medical-Visual-Question-answering (Med VQA)
In response to the escalating volume and complexity of radiological data, this research introduces an integrated framework for Medical Visual Question Answering (VQA) tailored specifically for radiology images. The study underscores the challenges in medical image analysis, emphasizing the need for a comprehensive VQA system to assist healthcare professionals in extracting crucial information from radiological scans. The proposed model leverages Word2Vec for question and answer embedding, facilitating a nuanced understanding of contextual relationships between medical queries and image content. Concurrently, VGG16, a deep convolutional neural network, is employed for robust image processing to extract relevant features crucial for accurate interpretation. A key innovation lies in the application of a stacked attention network, dynamically focusing on salient regions of medical images during the VQA process to enhance interpretability and performance. This integrated approach not only addresses challenges in medical image analysis but also establishes the groundwork for further advancements in the intersection of artificial intelligence and medical imaging.

Keywords : Visual Question Answering, Word2Vec, VGG16, Stacked Attention Networks, Tokenization, Embedding, Neural Networks
